# Energy Consumption Prediction using Machine Learning

This project predicts **hourly energy consumption** using various **machine learning regression models**.  
It uses the dataset from [Kaggle - Hourly Energy Consumption](https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption).

---

## ğŸ“ Dataset
**File:** `AEP_hourly.csv`  
- Timestamp-based hourly energy consumption data.  
- Missing values handled using forward fill.  
- Features include time-based variables (hour, day, month, year, weekday).

---

## ğŸ§  Models Used
| Model | Description |
|--------|--------------|
| Linear Regression | Simple baseline model |
| Decision Tree | Non-linear splits |
| Random Forest | Ensemble of decision trees |
| Gradient Boosting | Sequential boosting of weak learners |
| XGBoost | Optimized gradient boosting |
| LightGBM | Fast, efficient boosting library |
| SVR (RBF) | Support Vector Regression |
| Neural Network (MLP) | Deep learning approach |

---

## âš™ï¸ Model Evaluation Metrics
| Metric | Description |
|---------|--------------|
| MAE | Mean Absolute Error â€” average absolute prediction error |
| RMSE | Root Mean Squared Error â€” penalizes large errors |
| RÂ² | Coefficient of determination (1 is perfect) |
| MAPE (%) | Mean Absolute Percentage Error |
| Accuracy (%) | Derived metric = 100 - MAPE |

---

## ğŸ“Š Model Training Logs

ğŸ”¹ **Training Linear Regression...**  
Linear Regression â†’ MAE: 1823.35, RMSE: 2276.10, RÂ²: 0.2140  

ğŸ”¹ **Training Decision Tree...**  
Decision Tree â†’ MAE: 1596.19, RMSE: 2178.70, RÂ²: 0.2798  

ğŸ”¹ **Training Random Forest...**  
Random Forest â†’ MAE: 1315.68, RMSE: 1714.83, RÂ²: 0.5539  

ğŸ”¹ **Training Gradient Boosting...**  
Gradient Boosting â†’ MAE: 1330.99, RMSE: 1747.91, RÂ²: 0.5365  

ğŸ”¹ **Training XGBoost...**  
XGBoost â†’ MAE: 1409.86, RMSE: 1860.21, RÂ²: 0.4750  

ğŸ”¹ **Training LightGBM...**  
LightGBM â†’ MAE: 1349.19, RMSE: 1782.91, RÂ²: 0.5177  

ğŸ”¹ **Training SVR (RBF)...**  
SVR (RBF) â†’ MAE: 1710.58, RMSE: 2223.91, RÂ²: 0.2496  

ğŸ”¹ **Training Neural Network (MLP)...**  
Neural Network (MLP) â†’ MAE: 1594.37, RMSE: 2053.60, RÂ²: 0.3602  

---

## ğŸ“ˆ Summary of Results

| Model | MAE | RMSE | RÂ² |
|--------|------|------|----|
| Random Forest | 1315.68 | 1714.83 | 0.5539 |
| Gradient Boosting | 1330.99 | 1747.91 | 0.5365 |
| LightGBM | 1349.19 | 1782.91 | 0.5177 |
| XGBoost | 1409.86 | 1860.21 | 0.4750 |
| Neural Network (MLP) | 1594.37 | 2053.60 | 0.3602 |
| Decision Tree | 1596.19 | 2178.70 | 0.2798 |
| SVR (RBF) | 1710.58 | 2223.91 | 0.2496 |
| Linear Regression | 1823.35 | 2276.10 | 0.2140 |

---

## ğŸ§© Tech Stack
- Python (3.9+)
- Libraries: pandas, numpy, matplotlib, scikit-learn, xgboost, lightgbm
- IDE: PyCharm / Jupyter Notebook

---

## ğŸš€ How to Run
1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/energy-consumption-prediction.git
   cd energy-consumption-prediction
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Run the main script:
   ```bash
   python energy_prediction.py
   ```
4. View the model results printed in the console.

---

## ğŸ“ˆ Future Improvements
- Add hyperparameter tuning (GridSearchCV / Optuna)
- Incorporate weather data (temperature, humidity)
- Deploy as a web dashboard (Streamlit or Flask)

---

## Author
**Triston Aloyssius Marta** â€” Data Science & Statistics
ğŸ“§ Contact: tristonmarta@yahoo.com.sg
